---
title: 'Laboratorio 6: Análisis de sentimientos'
author: "Grupo 7"
date: "9/10/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Librerías
```{r}
library("readr") #Lee los archivos 
library("tm")  #Contiene tranformaciones para el text mining
library("wordcloud")
library(ggplot2) #para gráficos
library("SentimentAnalysis")
library("SnowballC") #Para sentiment analysis
library(tidytext) #otra para análisis de sentimientos.
```

# Descripción de los datos  
El dataset es un conjunto de reseñas de 1000 productos diferentes. El tamaño  del conjunto de datos es de 94 Megabytes, donde el conglomerado de datos se encuentra distribuido en un total de 25 columnas. 

El origen de la base de datos proviene de Datafiniti´s Product database e incluye datos de la reseña como el producto, el autor de la reseña, el título, la fecha, etc. 

El tipo de corpus es general dado que contiene diversos ejemplos del habla en idioma inglés que ha sido producido por personas de distintas edades, regiones y clases sociales. Así también se podría calificar como monolingue.
```{r}
#-------------------------------------------------
# Directorios para de cada integrante del grupo

#/Users/odalisrg/Documents/Semestre 6/Data Science/Laboratorio6DS
#/Users/quiebres/Documents/Ivan Maldonado/UVG/Sexto Semestre/Data Science/Laboratorio6DS
#/Users/hectorreyes/Documents/Mayra 
#-------------------------------------------------

# Se lee y se crea un dataframe del archivo
setwd("/Users/hectorreyes/Documents/Mayra ")
productos <- read_csv("GrammarandProductReviews.csv")
class(productos)
```




# Limpieza y preprocesamiento
Antes de comenzar a realizar la limpieza y preprocesamiento de los datos, fue necesario separar

## Creación del corpus
Para limpiar el texto de las opiniones de los productos realizadas por los clientes, decidimos solo tomar en cuenta la columna de reviews.text, ya que en esta parte del dataset se conglomeran las opiniones de los clientes. De esta manera, 
```{r}
texto <- paste(productos$reviews.title, collapse = " ")
opinion <- Corpus(VectorSource(texto))
```

## Limpieza y preprocesamiento del corpus
Para este apartado, se decidió transformar todas las letras mayúsculas a minúsculas para obtener un corpus más homogéneo. Con respecto a los números y a los stopwords, también se decidió eliminarlos ya que interferían en el análisis de palabras y facilitan a que el corpus reduzca su tamaño. Ahora bien, con los signos de puntuación se decidió eliminarlos todos, incluyendo aquellas combinaciones de signos que crean un emoticon. Decidimos basarnos solamente en la palabra y en su contexto dentro del corpus. 
```{r}
opinion <- tm_map(opinion, content_transformer(tolower))
opinion <- tm_map(opinion, content_transformer(removeNumbers))
opinion <- tm_map(opinion, content_transformer(removePunctuation))
opinion <- tm_map(opinion, stripWhitespace)
opinion <- tm_map(opinion, removeWords,stopwords(kind="en"))
```



# Análisis exploratorio

## Creación de matriz de documentación
```{r}
opinion_dtm <- DocumentTermMatrix(opinion)
```

## Encontrando la palabras con más frecuencia
```{r}
findFreqTerms(opinion_dtm, lowfreq=1000)
```

## Nube de palabas
Al momento de realizar la nube de palabras, vemos que las que más resaltan son palabras positivas, tales como _great, love, good, awesome, best_. También es importante mencionar que las palabras que están en color verde, tienen a mencionar un poco más del producto que se está evaluando.
```{r}
wordcloud(opinion, max.words=100, random.order= FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))
```
## Histograma de frecuencias
Este histograma muestra aquellas palabras que tienen por lo menos 1,500 repeticiones. Vemos que vuelven aparecer comentarios positivos, lo cual puede mostrar un indicio que la mayoría de opiniones que han realizado los clientes han sido positivas. Cabe mencionar que hace falta indagar más acera de las opiniones negativas.
```{r}
freq.reviews <- colSums(as.matrix(opinion_dtm))

wfReviews <- data.frame(word = names(freq.reviews), freq = freq.reviews)
head(wfReviews)


HistoR <- ggplot(subset(wfReviews, freq>1500), aes(x = reorder(word, -freq), y = freq)) +
          geom_bar(stat = "identity") + ggtitle("Palabras más frecuentes") +
          theme(axis.text.x=element_text(angle=45, hjust=1))
HistoR

```
## Histograma de palabras menos frecuentes
Con el fin de explorar que palabras, o si hay algún sentimiento que tenga menor frecuencia se realizó un histograma de las palabras con menor frecuencia. Explorando el data frame que se creó y el gráfico de barras, se tienen expresiones como 'aaaa', 'yummy' y variaciones del inglés como 'amaaaazin'. 
```{r}
freqWords <- apply(opinion_dtm,2,sum)
freqData <- data.frame(word=names(freqWords), frecuency=as.numeric(freqWords), stringsAsFactors = FALSE)
freqData<- freqData[order(freqData$frecuency, decreasing=TRUE), ]
barplot(tail(freqData$frecuency, n = 20), names.arg = tail(freqData$word, n = 20), main = "Palabras menos frecuentes", ylab = "Freq")

```

# Palabras negativas y positivas

```{r}
get_sentiments("bing")
```

# Análisis de sentimientos
```{r}
a_sent<-analyzeSentiment(opinion_dtm) 
b_sent<-convertToBinaryResponse(a_sent)
productos<-cbind(productos, b_sent)
```

# Análisis de datos 
## ¿Cuáles son los 10 productos de mejor calidad dado su review?

Se tienen los siguientes productos: 

```{r}
best<- productos[order(productos$PositivityGI, productos$PositivityHE, productos$PositivityLM, productos$PositivityQDAP, decreasing = TRUE), ]
bestP<- unique(best[,10])
head(bestP, 10)
```


## ¿Cuáles son los 10 productos de menor calidad dado su review?
Se tienen los siguientes productos, los cuales son los que tienen menor cantidad de buenos reviews.
```{r}
tail(best,10)
```

## ¿Cuáles son los usuarios que dan la mayor cantidad de reviews a distintos productos?
Los usuarios que dan mayor cantidad de reviews son: 
```{r}
usersDist <- productos[,c("reviews.id", "reviews.username", "name")]
usersDist <- distinct(usersDist, name, reviews.username)
usersDist <- sort(table(usersDist$reviews.username), decrease=T)
head(usersDist,10)
```
## ¿Cuáles son los usuarios que más reviews negativos y positivos dan en promedio?
hay que arreglar esto xd

```{r}
usersMost <- productos[,c("reviews.id", "reviews.username", "SentimentGI", "SentimentHE", "SentimentLM", "SentimentQDAP")]
u <-unique(as.character(usersMost$reviews.username))
p<-vector()
n<-vector()
for(i in 1:length(u)){
  a<-u[i]
  suppressWarnings(b<-usersMost[usersMost$reviews.username==a,c("SentimentGI", "SentimentHE", "SentimentLM", "SentimentQDAP")])
  
  p[i]<- sum(b == "positive")
  
  n[i]<- sum(b == "negative")
}

usersMost<-cbind(u, p, n, (p+n), abs(p-n))
head(usersMost[order(usersMost[,5], desc(usersMost[,4]), decreasing = T), ], 10)
```

## ¿Cuáles son los productores que tienen productos de mejor calidad?
Los productores que tienen productos de mejor calidad son:

```{r}
bestProv<- unique(best[,8])
head(bestProv, 10)

```

## ¿Cuáles son los productores que tienen productos de peor calidad?
Los productores que tienen productos de peor calidad son:
```{r}
tail(bestProv, 10)

```