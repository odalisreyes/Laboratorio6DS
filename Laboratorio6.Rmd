---
title: 'Laboratorio 6: Análisis de sentimientos'
author: "Grupo 7"
date: "9/10/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Librerías
```{r}
library("readr") #Lee los archivos 
library("tm")  #Contiene tranformaciones para el text mining
library("wordcloud")
library(ggplot2) #para gráficos
library("SentimentAnalysis")
library("SnowballC") #Para sentiment analysis
library(tidytext) #otra para análisis de sentimientos.
library("syuzhet")
library(dplyr) 
library(plyr)
```

# Descripción de los datos  
El dataset es un conjunto de reseñas de 1000 productos diferentes. El tamaño  del conjunto de datos es de 94 Megabytes, donde el conglomerado de datos se encuentra distribuido en un total de 25 columnas. 

El origen de la base de datos proviene de Datafiniti´s Product database e incluye datos de la reseña como el producto, el autor de la reseña, el título, la fecha, etc. 

El tipo de corpus es general dado que contiene diversos ejemplos del habla en idioma inglés que ha sido producido por personas de distintas edades, regiones y clases sociales. Así también se podría calificar como monolingue.
```{r}
#-------------------------------------------------
# Directorios para de cada integrante del grupo

#/Users/odalisrg/Documents/Semestre 6/Data Science/Laboratorio6DS
#/Users/quiebres/Documents/Ivan Maldonado/UVG/Sexto Semestre/Data Science/Laboratorio6DS
#/Users/hectorreyes/Documents/Mayra/Laboratorio6DS
#-------------------------------------------------

# Se lee y se crea un dataframe del archivo
setwd("/Users/quiebres/Documents/Ivan Maldonado/UVG/Sexto Semestre/Data Science/Laboratorio6DS")
productos <- read_csv("GrammarandProductReviews.csv")
class(productos)
```




# Limpieza y preprocesamiento
Antes de comenzar a realizar la limpieza y preprocesamiento de los datos, fue necesario separar

## Creación del corpus
Para limpiar el texto de las opiniones de los productos realizadas por los clientes, decidimos solo tomar en cuenta la columna de reviews.text, ya que en esta parte del dataset se conglomeran las opiniones de los clientes. De esta manera, 
```{r}
texto <- as.vector(productos$reviews.text)
set.seed(3)
porciento <- 0.5
sample <- sample(texto, length(texto)*porciento)

opinion <- paste(productos$reviews.text, collapse = " ")
opinion <- Corpus(VectorSource(texto))
```

## Limpieza y preprocesamiento del corpus
Para este apartado, se decidió transformar todas las letras mayúsculas a minúsculas para obtener un corpus más homogéneo. Con respecto a los números y a los stopwords, también se decidió eliminarlos ya que interferían en el análisis de palabras y facilitan a que el corpus reduzca su tamaño. Ahora bien, con los signos de puntuación se decidió eliminarlos todos, incluyendo aquellas combinaciones de signos que crean un emoticon. Decidimos basarnos solamente en la palabra y en su contexto dentro del corpus. 
```{r}
opinion <- tm_map(opinion, content_transformer(tolower))
opinion <- tm_map(opinion, content_transformer(removeNumbers))
opinion <- tm_map(opinion, content_transformer(removePunctuation))
opinion <- tm_map(opinion, stripWhitespace)
opinion <- tm_map(opinion, removeWords,stopwords(kind="en"))
```



# Análisis exploratorio

## Creación de matriz de documentación
```{r}
opinion_dtm <- DocumentTermMatrix(opinion)
```

## Encontrando la palabras con más frecuencia
```{r}
findFreqTerms(opinion_dtm, lowfreq=2000)
```

## Nube de palabas
Al momento de realizar la nube de palabras, vemos que las que más resaltan son palabras positivas, tales como _great, love, good, awesome, best_. También es importante mencionar que las palabras que están en color verde, tienen a mencionar un poco más del producto que se está evaluando.
```{r}
wordcloud(opinion, max.words=100, random.order= FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))
```
## Histograma de frecuencias
Este histograma muestra aquellas palabras que tienen por lo menos 1,500 repeticiones. Vemos que vuelven aparecer comentarios positivos, lo cual puede mostrar un indicio que la mayoría de opiniones que han realizado los clientes han sido positivas. Cabe mencionar que hace falta indagar más acera de las opiniones negativas.
```{r}
freq.reviews <- colSums(as.matrix(opinion_dtm))

wfReviews <- data.frame(word = names(freq.reviews), freq = freq.reviews)
head(wfReviews)


HistoR <- ggplot(subset(wfReviews, freq>6000), aes(x = reorder(word, -freq), y = freq)) +
          geom_bar(stat = "identity") + ggtitle("Palabras más frecuentes") +
          theme(axis.text.x=element_text(angle=45, hjust=1))
HistoR

```
## Histograma de palabras menos frecuentes
Con el fin de explorar que palabras, o si hay algún sentimiento que tenga menor frecuencia se realizó un histograma de las palabras con menor frecuencia. Explorando el data frame que se creó y el gráfico de barras, se tienen expresiones como 'timegot', 'againsorry' y  'muslin'. 
```{r}
freqWords <- apply(opinion_dtm,2,sum)
freqData <- data.frame(word=names(freqWords), frecuency=as.numeric(freqWords), stringsAsFactors = FALSE)
freqData<- freqData[order(freqData$frecuency, decreasing=TRUE), ]
barplot(tail(freqData$frecuency, n = 20), names.arg = tail(freqData$word, n = 20), main = "Palabras menos frecuentes", ylab = "Freq")

```
# Palabras positivas y negativas
```{r}

tokens <- data_frame(text = word) %>% unnest_tokens(word, text)
tokens %>%
  inner_join(get_sentiments("bing"))
```
# Clasificación de reviews

Se utilizó el paquete Syuzhet conjuntamente con el de SnowballC para la clasificación de reviews. Básicamente se creó un conjunto de vectores que contiene las reviews de los productos y a partir de la función *get_sentiment()* se puede clasificar de acuerdo a la calificación que se le asigna según los sentimientos en el review. Se consideraron 3 casos, siendo *value* una variable que representa la calificación otorgada por los sentimientos buenos o malos presentes en el review. Los sentimientos malos se asignan con valores negativos y los buenos con valores positivos, entonce se tiene que: 
* value>0: tiene mayor cantidad de sentimientos *buenos*, por ende, debe de tener una calificación mayor a 0.
* value=0: es neutro, dado que tiene la misma cantidad de sentimientos buenos y malos.
* value<0: tiene mayor cantidad de sentimientos *malos*.

##Positivos
```{r}

#AFFINN <-get_sentiments("afinn")
#productos <-unique(productos)

#review_words <- productos %>%
 # select(name, reviews.text) %>%
  #unnest_tokens(word, reviews.text) 
 

#reviews_sentiment <- review_words %>%
 # inner_join(AFINN, by = "word") %>%
  #group_by(name) %>%
  #summarize(sentiment = mean(afinn_score))

#reviews_sentiment


word <- as.vector(productos$reviews.text)
set.seed(3)
porciento <- 0.05
word <- sample(word, length(word)*porciento)
emotion <-get_nrc_sentiment(word)
value <- get_sentiment(word)
mostPos <- word[value == max(value)]
mostNeg <- word[value == min(value)]

#Positivos
positive <- word[value>0]
head(positive)
```


##Negativos
```{r}
#Positivos
negative <- word[value<0]
head(negative)
```
## Neutros
```{r}
#Positivos
neutral <- word[value==0]
head(neutral)
```

# Análisis de sentimientos
```{r}
a_sent<-analyzeSentiment(opinion_dtm) 
b_sent<-convertToBinaryResponse(a_sent)
productos<-cbind(productos, b_sent)
```

# Análisis de datos 


## ¿Cuáles son los 10 productos de mejor calidad dado su review?

Se tienen los siguientes productos: 

```{r}
best<- productos[order(productos$PositivityGI, productos$PositivityHE, productos$PositivityLM, productos$PositivityQDAP, decreasing = TRUE), ]
bestP<- unique(best[,10])
head(bestP, 10)

bett <- ddply(productos, .(name), summarize, sum=sum(PositivityGI,PositivityHE,PositivityLM,PositivityQDAP))
bett <- bett[order(bett$sum, decreasing=TRUE),]
unique(head(bett,10))
```


## ¿Cuáles son los 10 productos de menor calidad dado su review?
Se tienen los siguientes productos, los cuales son los que tienen menor cantidad de buenos reviews.
```{r}
unique(tail(bett,10))
```

## ¿Cuáles son los usuarios que dan la mayor cantidad de reviews a distintos productos?
Los usuarios que dan mayor cantidad de reviews son: 
```{r}
usersDist <- productos[,c("reviews.id", "reviews.username", "name")]
usersDist <- distinct(usersDist, name, reviews.username)
usersDist <- sort(table(usersDist$reviews.username), decrease=T)
head(usersDist,10)
```
## ¿Cuáles son los usuarios que más reviews negativos y positivos dan en promedio?
hay que arreglar esto xd

```{r}
usersMost <- productos[,c("reviews.id", "reviews.username", "SentimentGI", "SentimentHE", "SentimentLM", "SentimentQDAP")]
u <-unique(as.character(usersMost$reviews.username))
p<-vector()
n<-vector()
for(i in 1:length(u)){
  a<-u[i]
  suppressWarnings(b<-usersMost[usersMost$reviews.username==a,c("SentimentGI", "SentimentHE", "SentimentLM", "SentimentQDAP")])
  
  p[i]<- sum(b == "positive")
  
  n[i]<- sum(b == "negative")
}

usersMost<-cbind(u)
head(usersMost, 10)
```

## ¿Cuáles son los productores que tienen de mejor calidad?
Los productores que tienen productos de mejor calidad son:

```{r}
bestProv <- ddply(productos, .(manufacturer), summarize, sum=sum(PositivityGI,PositivityHE,PositivityLM,PositivityQDAP))
bestProv <- bestProv[order(bestProv$sum, decreasing=TRUE),]
unique(head(bestProv,10))
```

## ¿Cuáles son los productores que tienen productos de peor calidad?
Los productores que tienen productos de peor calidad son:
```{r}
tail(bestProv, 10)

```


## Imagine que usted es analista de negocios y que está realizando este análisis para el productor que tiene más productos con malos reviews ¿Qué le propondría a esta empresa para mejorar sus productos? Puede basar su análisis en la frecuencia de las palabras de las opiniones.

Según nuestro análisis, el productor es "Yosemite Home Decor". Al momento de inspeccionar las palabras utilizadas en sus reviews se tienen los siguientes puntos importantes a destacar: 
* Esta empresa solamente tiene un review, lo cual afecta bastante dado que los parámetros utilizados para obtener el productor cuyos productos han tenido malos reviews se relacionan con la puntuación total obtenida con el análisis de sentimientos. 
* Al analizar la review se obtuvo que el cliente no quedó satisfecho dado que esperaba algo más.
* Se le recomienta al productor que mejore la calidad del material, así como tratar de cumplir con lo ofrecido en la imagen del producto dado que el cliente ni siquiera probó al producto al ver que no tenían la misma apariencia.

```{r}
worstP <- productos[productos$manufacturer=="Yosemite Home Decor", ]
```



